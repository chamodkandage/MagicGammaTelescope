# MagicGammaTelescope
Machine learning project (Data Science)
Bock,R.. (2007). MAGIC Gamma Telescope. UCI Machine Learning Repository. https://doi.org/10.24432/C52C8B.
This repository contains the code and resources for a machine learning freelancing project. The project aims to develop data science skills and involves classification tasks using various algorithms and techniques.


# Introduction
The goal of this project is to apply machine learning algorithms for classification tasks. The project includes data preprocessing, model training, evaluation, and result analysis. The following libraries and tools were used in this project:

NumPy: A library for numerical computing in Python.<br>
Pandas: A library for data manipulation and analysis.<br>
Matplotlib: A library for data visualization.<br>
Scikit-learn: A machine learning library for Python.<br>
Imbalanced-learn: A library for dealing with imbalanced datasets.<br>
TensorFlow: A framework for building and training machine learning models.<br>

# Usage
The project consists of multiple scripts and notebooks. Each script/notebook focuses on a specific task or technique. Here is a brief description of the files in this repository:

Magic_Telescope.ipynb: Colabatory page demonstrating data preprocessing steps.
README.md: Description.
Feel free to explore and run the notebooks to understand the steps involved in data preprocessing, model training, and evaluation.

# Data Preprocessing
Data preprocessing is an essential step in machine learning projects. In the data_preprocessing.ipynb notebook, you will find code and explanations for common preprocessing tasks such as data cleaning, feature scaling, and handling imbalanced datasets using the RandomOverSampler technique.

# Model Training and Evaluation
In the model_training.ipynb notebook, various machine learning algorithms are applied to the preprocessed data. The notebook demonstrates the use of K-Nearest Neighbors (KNN), Logistic Regression, Support Vector Machines (SVM), and TensorFlow for classification tasks. Model evaluation is performed using metrics such as accuracy, precision, recall, and F1-score.

# Results and Analysis
The results of the trained models, along with analysis and insights, are presented in the notebooks. The classification report, confusion matrix, and visualizations are used to assess the performance of the models and gain a deeper understanding of the data.

# Contributing
Contributions to this project are welcome. If you have any suggestions, improvements, or bug fixes, please submit a pull request. For major changes, please open an issue first to discuss the proposed changes.
